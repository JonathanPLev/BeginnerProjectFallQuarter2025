{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b730d485-9d64-4004-81d5-c99a66a49a84",
   "metadata": {},
   "source": [
    "1: Convert pdf to an image. Store the page as an image  \n",
    "\n",
    "2: img processing techniques like grayscale and diagram removal  \n",
    "\n",
    "3: bounding boxes per word  \n",
    "\n",
    "4: combine boxes into lines of text  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "074ebfdf-0115-4edf-855a-fac3a1e03e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PyPDF2\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c53b5-1cfd-44a2-be68-e2c4e689f2be",
   "metadata": {},
   "source": [
    "# Step 1: Insert pdf path and save as image  \n",
    "Must install poppler: https://github.com/oschwartz10612/poppler-windows/releases  \n",
    "Follow directions to add poppler:  \n",
    "- Download poppler as .zip, then extract all\n",
    "- Press Win + R, type sysdm.cpl, hit Enter.\n",
    "- Go to Advanced → Environment Variables.\n",
    "- Under User variables, find Path → Edit → New.\n",
    "- Paste: C:\\pasteYourPathHere\\poppler-23.10.0\\bin\n",
    "\n",
    "Restart terminal, verify instalation: pdftoppm -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a74fc29a-d8e3-4811-a0ee-a5a01d16430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "pdf_path = r\"C:\\Users\\dkhun\\UC Davis\\AISC Github repository\\BeginnerProjectFallQuarter2025\\data\\raw_pdfs\\textbook_pdf_6.pdf\"\n",
    "pdf_image = convert_from_path(pdf_path)\n",
    "\n",
    "pages = list(pdf_image)\n",
    "print(len(pages))\n",
    "#pages[0].show()\n",
    "\n",
    "#resize image to standard?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0da74e6-645a-4fe9-908a-1d2da8fbe76b",
   "metadata": {},
   "source": [
    "# Step 2: Image processing shi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073dc47c-f333-4ce4-a4a3-1c583a3ed4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image to NumPY array in order to apply filters\n",
    "opencv_page1 = np.array(pages[0])\n",
    "opencv_page1 = cv2.cvtColor(opencv_page1, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#Apply grayscale, bilateral (to retain edges better), adaptive binary filter\n",
    "gray_page1 = cv2.cvtColor(opencv_page1, cv2.COLOR_BGR2GRAY)\n",
    "#If overblurred, decrease sigmaColor and sigmaSpace (to 50?)\n",
    "bilateral_page1 = cv2.bilateralFilter(gray_page1, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "binary_filter = cv2.adaptiveThreshold(\n",
    "    bilateral_page1, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, 5)\n",
    "#gaussian_blur_page1 = cv2.GaussianBlur(gray_page1,(3,3),0)\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "morphological_filter = cv2.morphologyEx(binary_filter, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "#Improve edge sharpness by subtracting low freq parts from original image\n",
    "#This leaves high frequency (edges)\n",
    "#Then, add high freq back to original to get sharper edges\n",
    "high_freq_page1 = cv2.subtract(gray_page1, bilateral_page1) #chat reblurred the image, I used gaussian_blur_page1\n",
    "sharpen_strength = 15.0\n",
    "sharpened_page1 = cv2.addWeighted(gray_page1, 1.0, high_freq_page1, sharpen_strength, 0)\n",
    "\n",
    "\n",
    "#Convert the opencv file back to PIL so that it can be viewed\n",
    "test = Image.fromarray(sharpened_page1)\n",
    "test1 = Image.fromarray(morphological_filter)\n",
    "test.show()\n",
    "test1.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac4b8d",
   "metadata": {},
   "source": [
    "# Monday 10/20 Meeting  \n",
    "Want bounding boxes merged into lines. Each line is a specific png image  \n",
    "- Use pandas dataframe to represent data (makes it more efficient)  \n",
    "- Use pd.readcsv() ??  \n",
    "- csv (excel) file has data for things like left_bounding, width, height, confidence, and text PER WORD BOX  \n",
    "- Important: print(df.colums) says names of colums  \n",
    "- Important: print(df.head(n)) gives all the data for n rows  \n",
    "To access all the values in certain columns (ex: left bounding), use df_left = df['left_bounding'][][]  \n",
    "- Or use df_column_names = df[['col1,'col2','coln']]  \n",
    "For loops:  \n",
    "- \"for idx,row in df.iterrows() is used to iterate through the rows  \n",
    "- Initialize right pixel as negative infinity  \n",
    "- if idx=0: right_pixel = row['left'] + row['width']\n",
    "     - right pixel = left bounding + width  \n",
    "     - create threshold for if two words are close enough (sequential) and test vetical distance(same line)  \n",
    "- Make else contained within the for loop: save segment of pdf (segment=boxed line of text), specify them by combined values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adfd14b",
   "metadata": {},
   "source": [
    "# To Do:   \n",
    "1) Filtering: get text clear and remove images/diagrams  \n",
    "- sharp edges for text  \n",
    "2) Find and implement a library for bounding boxes  \n",
    "3) write bandas logic to create single-line boxes (merging of individual boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8862ec-7b5b-4401-a51c-5fd1984a8804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
