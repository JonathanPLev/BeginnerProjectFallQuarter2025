{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b730d485-9d64-4004-81d5-c99a66a49a84",
   "metadata": {},
   "source": [
    "1: Convert pdf to an image. Store the page as an image  \n",
    "\n",
    "2: img processing techniques like grayscale and diagram removal  \n",
    "\n",
    "3: bounding boxes per word  \n",
    "\n",
    "4: combine boxes into lines of text  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074ebfdf-0115-4edf-855a-fac3a1e03e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PyPDF2\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c53b5-1cfd-44a2-be68-e2c4e689f2be",
   "metadata": {},
   "source": [
    "Must install poppler: https://github.com/oschwartz10612/poppler-windows/releases  \n",
    "Follow directions to add poppler:  \n",
    "- Download poppler as .zip, then extract all\n",
    "- Press Win + R, type sysdm.cpl, hit Enter.\n",
    "- Go to Advanced → Environment Variables.\n",
    "- Under User variables, find Path → Edit → New.\n",
    "- Paste: C:\\pasteYourPathHere\\poppler-23.10.0\\bin\n",
    "\n",
    "Restart terminal, verify instalation: pdftoppm -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd92ede-9e3a-4635-994f-df02836fdffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Options:\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 \n"
     ]
    }
   ],
   "source": [
    "def load(pdf_path):\n",
    "    pdf_image = convert_from_path(pdf_path)\n",
    "    pages = list(pdf_image)\n",
    "    print('Page Options:')\n",
    "    for i in range(len(pages)):\n",
    "        print(i,end = \" \")\n",
    "    print()\n",
    "    return pages\n",
    "\n",
    "#convert page to numpy array in order to apply filters\n",
    "def retreive_page(pages, page_number):\n",
    "    opencv_pageN = np.array(pages[page_number])\n",
    "    opencv_pageN = cv2.cvtColor(opencv_pageN, cv2.COLOR_RGB2BGR)\n",
    "    return opencv_pageN\n",
    "    \n",
    "#For a given pdf, replace the path. Then, select the page you want to extract\n",
    "pdf_path = r\"C:\\Users\\dkhun\\UC Davis\\AISC Github repository\\BeginnerProjectFallQuarter2025\\data\\raw_pdfs\\textbook_pdf_3_includes_diagrams.pdf\"\n",
    "pages = load(pdf_path)\n",
    "opencv_pageN = retreive_page(pages,1);\n",
    "pageN = Image.fromarray(opencv_pageN)\n",
    "pageN.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0da74e6-645a-4fe9-908a-1d2da8fbe76b",
   "metadata": {},
   "source": [
    "# Step 2: Image processing   \n",
    "### A typical pipeline looks like this:\n",
    "\n",
    "1) Grayscale conversion → Reduces to single channel.\n",
    "\n",
    "2) Noise reduction (Gaussian or bilateral filter).\n",
    "\n",
    "3) Morphological operations / small artifact removal → Fill gaps, remove small holes.\n",
    "\n",
    "4) Sharpening / high-frequency mask → Enhances the text edges.\n",
    "\n",
    "5) Deskew / rescale / thresholding → Final normalization for OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "073dc47c-f333-4ce4-a4a3-1c583a3ed4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: save test.png\n",
      "Saved: pdf3 grayscale.png\n",
      "Saved: pdf3 binary.png\n"
     ]
    }
   ],
   "source": [
    "def apply_grayscale(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "def apply_bilateral(image):   #method of smoothing while preserving edges\n",
    "    bilateral = cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    return bilateral\n",
    "    #If overblurred, decrease sigmaColor and sigmaSpace (to 50?)\n",
    "\n",
    "def apply_gaussian_blur(image):      #smooths image uniformly\n",
    "    gaussian = cv2.GaussianBlur(image,(3,3),0)\n",
    "    return gaussian\n",
    "\n",
    "def apply_morphological_closing(image, ksize):\n",
    "    kernel = np.ones((ksize, ksize), np.uint8)   #ksize is strength. Closing performs dilation then erosion\n",
    "    closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    return closing\n",
    "\n",
    "def apply_dilation(image, ksize):\n",
    "    kernel = np.ones((ksize, ksize), np.uint8)  # ksize controls strength\n",
    "    dilated = cv2.dilate(image, kernel, iterations=1)\n",
    "    return dilated\n",
    "    \n",
    "def apply_sharpen(image):   #try different sharpening strength?\n",
    "    low_freq = apply_bilateral(image)\n",
    "    high_freq = cv2.subtract(image, low_freq)\n",
    "    sharpen_strength = 15\n",
    "    sharpened = cv2.addWeighted(image, 1.0, high_freq, sharpen_strength, 0)\n",
    "    return sharpened\n",
    "    #Improve edge sharpness by subtracting low freq parts from original image\n",
    "    #This leaves high frequency (edges)\n",
    "    #Then, add high freq back to original to get sharper edges\n",
    "\n",
    "def apply_binary(image):\n",
    "    binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 5)\n",
    "    #Adusting params: ... n,n) corresponds to ... neighborhood_averaging, threshold\n",
    "    #Decreasing threshold makes more black\n",
    "    #increasing neighborhood_averaging increases smoothing\n",
    "    return binary\n",
    "    #binary should be done last\n",
    "\n",
    "def save_image(opencv_array, label):\n",
    "    file_name = f'{label}.png'\n",
    "    save_img = Image.fromarray(opencv_array)\n",
    "    save_img.save(file_name)\n",
    "    save_img.show()\n",
    "    print(f'Saved: {file_name}')\n",
    "\n",
    "def filter(image, label):\n",
    "    filtered_image = apply_gaussian_blur(apply_binary(apply_grayscale(image)))\n",
    "    save_image(filtered_image, label)\n",
    "    return filtered_image\n",
    "\n",
    "#Filters of choice:\n",
    "gray_binary_gaussian = apply_gaussian_blur(apply_binary(apply_grayscale(opencv_pageN)))\n",
    "#best combination so far has been: gray --> binary --> gaussian\n",
    "\n",
    "test = filter(opencv_pageN,'save test')\n",
    "pdf3_gray = apply_grayscale(opencv_pageN)\n",
    "#pdf3_gaussian = apply_gaussian_blur(opencv_pageN)\n",
    "pdf3_gray_binary = apply_binary(gray_binary_gaussian)\n",
    "\n",
    "save_image(pdf3_gray,'pdf3 grayscale')\n",
    "save_image(pdf3_gray_binary,'pdf3 binary')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4fa678",
   "metadata": {},
   "source": [
    "### Image is now filtered for clarity, but we want to remove any remaining diagrams now.  \n",
    "Going to leave this alone for now  \n",
    "Input to .ser,detectRegions is grayscale opencv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07223477-63b0-4ea8-92c5-4be6b1dd0f31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gray_binary_gaussian' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m img = \u001b[43mgray_binary_gaussian\u001b[49m     \u001b[38;5;66;03m#this is the txtbk_pdf_6 doc that img processing was tested on\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#the following is txtbk_pdf_3 which includes diagrams\u001b[39;00m\n\u001b[32m      4\u001b[39m img2_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdkhun\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUC Davis\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mAISC Github repository\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBeginnerProjectFallQuarter2025\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mraw_pdfs\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mtextbook_pdf_3_includes_diagrams.pdf\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'gray_binary_gaussian' is not defined"
     ]
    }
   ],
   "source": [
    "img = gray_binary_gaussian     #this is the txtbk_pdf_6 doc that img processing was tested on\n",
    "\n",
    "#the following is txtbk_pdf_3 which includes diagrams\n",
    "img2_path = r\"C:\\Users\\dkhun\\UC Davis\\AISC Github repository\\BeginnerProjectFallQuarter2025\\data\\raw_pdfs\\textbook_pdf_3_includes_diagrams.pdf\"\n",
    "pdf_image2 = convert_from_path(img2_path)\n",
    "pages = list(pdf_image2)\n",
    "print(len(pages))\n",
    "opencv_page3 = np.array(pages[2])\n",
    "opencv_page3 = cv2.cvtColor(opencv_page3, cv2.COLOR_RGB2BGR)\n",
    "cv2.imshow('Page 3',opencv_page3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#the third page of the pdf is now obtained\n",
    "#this process should be streamlined into a function later\n",
    "img2 = apply_binary(apply_grayscale(opencv_page3))     #applying binary filter is creating a ton of noise atm\n",
    "#img2 = apply_gaussian_blur(apply_binary(apply_grayscale(opencv_page3)))\n",
    "save_image(img2,'pdf_3_with_diagrams')\n",
    "print(type(img2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfe900",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MSER(image):\n",
    "    mser = cv2.MSER_create(delta=4, min_area = 50)\n",
    "    regions, bboxes = mser.detectRegions(image)\n",
    "    \n",
    "    for box in bboxes:\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0,255,0),1)\n",
    "    \n",
    "    cv2.imshow('MSER Regions', image)\n",
    "   #cv2.resizeWindow('MSER Regions', 1500, 900)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "MSER(pdf3_gray)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac4b8d",
   "metadata": {},
   "source": [
    "# Monday 10/20 Meeting  \n",
    "Want bounding boxes merged into lines. Each line is a specific png image  \n",
    "- Use pandas dataframe to represent data (makes it more efficient)  \n",
    "- Use pd.readcsv() ??  \n",
    "- csv (excel) file has data for things like left_bounding, width, height, confidence, and text PER WORD BOX  \n",
    "- Important: print(df.colums) says names of colums  \n",
    "- Important: print(df.head(n)) gives all the data for n rows  \n",
    "To access all the values in certain columns (ex: left bounding), use df_left = df['left_bounding'][][]  \n",
    "- Or use df_column_names = df[['col1,'col2','coln']]  \n",
    "For loops:  \n",
    "- \"for idx,row in df.iterrows() is used to iterate through the rows  \n",
    "- Initialize right pixel as negative infinity  \n",
    "- if idx=0: right_pixel = row['left'] + row['width']\n",
    "     - right pixel = left bounding + width  \n",
    "     - create threshold for if two words are close enough (sequential) and test vetical distance(same line)  \n",
    "- Make else contained within the for loop: save segment of pdf (segment=boxed line of text), specify them by combined values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adfd14b",
   "metadata": {},
   "source": [
    "# To Do:   \n",
    "1) Filtering: get text clear and remove images/diagrams  \n",
    "- sharp edges for text  \n",
    "2) Find and implement a library for bounding boxes  \n",
    "3) write bandas logic to create single-line boxes (merging of individual boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8862ec-7b5b-4401-a51c-5fd1984a8804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beginnerprojectfallquarter2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
