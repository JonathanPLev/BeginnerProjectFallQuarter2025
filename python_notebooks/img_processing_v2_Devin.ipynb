{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b730d485-9d64-4004-81d5-c99a66a49a84",
   "metadata": {},
   "source": [
    "1: Convert pdf to an image. Store the page as an image  \n",
    "\n",
    "2: img processing techniques like grayscale and diagram removal  \n",
    "\n",
    "3: bounding boxes per word  \n",
    "\n",
    "4: combine boxes into lines of text  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074ebfdf-0115-4edf-855a-fac3a1e03e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PyPDF2\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c53b5-1cfd-44a2-be68-e2c4e689f2be",
   "metadata": {},
   "source": [
    "# Step 1: Insert pdf path and save as image  \n",
    "Must install poppler: https://github.com/oschwartz10612/poppler-windows/releases  \n",
    "Follow directions to add poppler:  \n",
    "- Download poppler as .zip, then extract all\n",
    "- Press Win + R, type sysdm.cpl, hit Enter.\n",
    "- Go to Advanced → Environment Variables.\n",
    "- Under User variables, find Path → Edit → New.\n",
    "- Paste: C:\\pasteYourPathHere\\poppler-23.10.0\\bin\n",
    "\n",
    "Restart terminal, verify instalation: pdftoppm -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a74fc29a-d8e3-4811-a0ee-a5a01d16430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "pdf_path = r\"C:\\Users\\dkhun\\UC Davis\\AISC Github repository\\BeginnerProjectFallQuarter2025\\data\\raw_pdfs\\textbook_pdf_6.pdf\"\n",
    "pdf_image = convert_from_path(pdf_path)\n",
    "\n",
    "pages = list(pdf_image)\n",
    "print(len(pages))\n",
    "\n",
    "#convert image to numpy array in order to apply filters\n",
    "opencv_page1 = np.array(pages[0])\n",
    "opencv_page1 = cv2.cvtColor(opencv_page1, cv2.COLOR_RGB2BGR)\n",
    "#resize image to standard?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0da74e6-645a-4fe9-908a-1d2da8fbe76b",
   "metadata": {},
   "source": [
    "# Step 2: Image processing   \n",
    "### A typical pipeline looks like this:\n",
    "\n",
    "1) Grayscale conversion → Reduces to single channel.\n",
    "\n",
    "2) Noise reduction (Gaussian or bilateral filter).\n",
    "\n",
    "3) Morphological operations / small artifact removal → Fill gaps, remove small holes.\n",
    "\n",
    "4) Sharpening / high-frequency mask → Enhances the text edges.\n",
    "\n",
    "5) Deskew / rescale / thresholding → Final normalization for OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073dc47c-f333-4ce4-a4a3-1c583a3ed4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: save test.png\n"
     ]
    }
   ],
   "source": [
    "def apply_grayscale(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "def apply_bilateral(image):   #method of smoothing while preserving edges\n",
    "    bilateral = cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    return bilateral\n",
    "    #If overblurred, decrease sigmaColor and sigmaSpace (to 50?)\n",
    "\n",
    "def apply_gaussian_blur(image):      #smooths image uniformly\n",
    "    gaussian = cv2.GaussianBlur(image,(3,3),0)\n",
    "    return gaussian\n",
    "\n",
    "def apply_morphological_closing(image, ksize):\n",
    "    kernel = np.ones((ksize, ksize), np.uint8)   #ksize is strength. Closing performs dilation then erosion\n",
    "    closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    return closing\n",
    "\n",
    "def apply_dilation(image, ksize):\n",
    "    kernel = np.ones((ksize, ksize), np.uint8)  # ksize controls strength\n",
    "    dilated = cv2.dilate(image, kernel, iterations=1)\n",
    "    return dilated\n",
    "    \n",
    "def apply_sharpen(image):   #try different sharpening strength?\n",
    "    low_freq = apply_bilateral(image)\n",
    "    high_freq = cv2.subtract(image, low_freq)\n",
    "    sharpen_strength = 15\n",
    "    sharpened = cv2.addWeighted(image, 1.0, high_freq, sharpen_strength, 0)\n",
    "    return sharpened\n",
    "    #Improve edge sharpness by subtracting low freq parts from original image\n",
    "    #This leaves high frequency (edges)\n",
    "    #Then, add high freq back to original to get sharper edges\n",
    "\n",
    "def apply_binary(image):\n",
    "    binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, 1)\n",
    "    #Adusting params: ... n,n) corresponds to ... neighborhood_averaging, threshold\n",
    "    #Decreasing threshold makes more black\n",
    "    #increasing neighborhood_averaging increases smoothing\n",
    "    return binary\n",
    "    #binary should be done last\n",
    "\n",
    "def save_image(opencv_array, label):\n",
    "    file_name = f'{label}.png'\n",
    "    img = Image.fromarray(opencv_array)\n",
    "    img.save(file_name)\n",
    "    img.show()\n",
    "    print(f'Saved: {file_name}')\n",
    "\n",
    "def filter(image, label):\n",
    "    filtered_image = apply_gaussian_blur(apply_binary(apply_grayscale(image)))\n",
    "    save_image(filtered_image, label)\n",
    "    return filtered_image\n",
    "\n",
    "#Filters of choice:\n",
    "gray_binary_gaussian = apply_gaussian_blur(apply_binary(apply_grayscale(opencv_page1)))\n",
    "#best combination so far has been: gray --> binary --> gaussian\n",
    "\n",
    "test = filter(opencv_page1,'save test')\n",
    "\n",
    "#save_image(gray_binary_gaussian,'gray, binary, gaussian, then dilation, binary again')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4fa678",
   "metadata": {},
   "source": [
    "### Image is now filtered for clarity, but we want to remove any remaining diagrams now.  \n",
    "Going to leave this alone for now  \n",
    "Input to .ser,detectRegions is grayscale opencv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1edfe900",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m mser = cv2.MSER_create()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m regions, bboxes = mser.detectRegions(\u001b[43mimage\u001b[49m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m bboxes:\n\u001b[32m      5\u001b[39m     x, y, w, h = box\n",
      "\u001b[31mNameError\u001b[39m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "mser = cv2.MSER_create()\n",
    "regions, bboxes = mser.detectRegions(image)\n",
    "\n",
    "for box in bboxes:\n",
    "    x, y, w, h = box\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0,255,0),1)\n",
    "\n",
    "cv2.imshow('MSER Regions', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac4b8d",
   "metadata": {},
   "source": [
    "# Monday 10/20 Meeting  \n",
    "Want bounding boxes merged into lines. Each line is a specific png image  \n",
    "- Use pandas dataframe to represent data (makes it more efficient)  \n",
    "- Use pd.readcsv() ??  \n",
    "- csv (excel) file has data for things like left_bounding, width, height, confidence, and text PER WORD BOX  \n",
    "- Important: print(df.colums) says names of colums  \n",
    "- Important: print(df.head(n)) gives all the data for n rows  \n",
    "To access all the values in certain columns (ex: left bounding), use df_left = df['left_bounding'][][]  \n",
    "- Or use df_column_names = df[['col1,'col2','coln']]  \n",
    "For loops:  \n",
    "- \"for idx,row in df.iterrows() is used to iterate through the rows  \n",
    "- Initialize right pixel as negative infinity  \n",
    "- if idx=0: right_pixel = row['left'] + row['width']\n",
    "     - right pixel = left bounding + width  \n",
    "     - create threshold for if two words are close enough (sequential) and test vetical distance(same line)  \n",
    "- Make else contained within the for loop: save segment of pdf (segment=boxed line of text), specify them by combined values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adfd14b",
   "metadata": {},
   "source": [
    "# To Do:   \n",
    "1) Filtering: get text clear and remove images/diagrams  \n",
    "- sharp edges for text  \n",
    "2) Find and implement a library for bounding boxes  \n",
    "3) write bandas logic to create single-line boxes (merging of individual boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8862ec-7b5b-4401-a51c-5fd1984a8804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beginnerprojectfallquarter2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
